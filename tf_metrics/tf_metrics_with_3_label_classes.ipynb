{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates PRECISION and RECALL per CLASS in a MULTI-CLASS scenario where\n",
    "# number of classes is more than 2 (It is 3 in the example below)\n",
    "# It also calculates F1 Score per class.\n",
    "# And it even calculates ACCURACY on the entire data set given.\n",
    "\n",
    "# IMPORTANT NOTES:\n",
    "# 1) Since the same tensor is used for accuracy/precision/recall calculation for\n",
    "#    both train and test sets, you need to reset local variables in each tf.metrics\n",
    "#    tensor before using it for - say - test set after using it for train set.\n",
    "#    Otherwise, your - say - test results will be a combination of train and test results\n",
    "# 2) You could have used the default tf local variable initializer. But it initializes all\n",
    "#    local variables. It does not heart to use it in the beginning but before re-using \n",
    "#    the tf.metric function, you just need to reset the corresponding local variables\n",
    "# 3) Note that tf.metrics.accuracy(..) function works fine with multi class scenarios.\n",
    "#    However, precision and recall functions are not working when there are more than 2 classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSUMPTIONS: (Otherwise, decode_csv function needs update)\n",
    "# 1) The first column is NOT a feature. (It is most probably a training example ID or similar)\n",
    "# 2) The last column is always the label. And there is ONLY 1 column that represents the label.\n",
    "#    If more than 1 column represents the label, decode_csv() function needs update \n",
    "# 3) The first row is assumed to include names of the data types (i.e. feature name, label, etc.) \n",
    "#    so it is skipped\n",
    "\n",
    "# UPDATE record_default IN EACH PROJECT (depending on default values for each column)\n",
    "# Determine default values for each column in case data is missing\n",
    "record_defaults = [[\"\"], [0.0], [0.0], [0.0], [0.0], [0.0], [0]]\n",
    "\n",
    "def decode_csv(line):\n",
    "    parsed_line = tf.decode_csv(line, record_defaults)\n",
    "    label = parsed_line[-1:]          # last column is label\n",
    "    del parsed_line[-1]               # delete the last element from the list   (label column)\n",
    "    del parsed_line[0]                # even delete the first element bcz it is assumed NOT to be a feature\n",
    "    features = tf.stack(parsed_line)  # Stack features so that you can later vectorize forward prop., etc.\n",
    "    label = tf.stack(label)           # Needed bcz labels consist of 2 columns\n",
    "    batch_to_return = features, label\n",
    "\n",
    "    return batch_to_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch nr:  0 class:  0   Precision:  1.0   Recall:     0.6666667   Model Accuracy:  0.6666667\n",
      "Batch nr:  0 class:  1   Precision:  0.0   Recall:     0.0   Model Accuracy:  0.6666667\n",
      "Batch nr:  0 class:  2   Precision:  0.0   Recall:     0.0   Model Accuracy:  0.6666667\n",
      "Batch nr:  1 class:  0   Precision:  0.8   Recall:     0.6666667   Model Accuracy:  0.5833333\n",
      "Batch nr:  1 class:  1   Precision:  0.75   Recall:     0.5   Model Accuracy:  0.5833333\n",
      "Batch nr:  1 class:  2   Precision:  0.0   Recall:     0.0   Model Accuracy:  0.5833333\n",
      "Batch nr:  2 class:  0   Precision:  0.6666667   Recall:     0.6666667   Model Accuracy:  0.5\n",
      "Batch nr:  2 class:  1   Precision:  0.42857143   Recall:     0.5   Model Accuracy:  0.5\n",
      "Batch nr:  2 class:  2   Precision:  0.4   Recall:     0.33333334   Model Accuracy:  0.5\n",
      "All data processed.\n",
      "\n",
      "Summary\n",
      "\n",
      "class:  0   Precision:   0.6666667   Recall:  0.6666667   F1 Score:  0.6666667   Model Accuracy:  0.5\n",
      "class:  1   Precision:   0.42857143   Recall:  0.5   F1 Score:  0.46153846   Model Accuracy:  0.5\n",
      "class:  2   Precision:   0.4   Recall:  0.33333334   F1 Score:  0.36363637   Model Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()  \n",
    "\n",
    "# Assume that following values are our predictions from our model\n",
    "train_predictions = [[[0], [0], [0], [0], [1], [2]],\n",
    "                     [[1], [2], [1], [1], [0], [2]],\n",
    "                     [[2], [2], [0], [1], [1], [1]]]\n",
    "\n",
    "num_classes = 3\n",
    "minibatch_size = 6\n",
    "file_names = [\"train1_with_3_label_classes.csv\"]\n",
    "\n",
    "precision_per_class = [0] * num_classes\n",
    "update_precision_per_class = [[]] * num_classes\n",
    "recall_per_class = [0] * num_classes\n",
    "update_recall_per_class = [[]] * num_classes\n",
    "f1_score_per_class = [0] * num_classes\n",
    "\n",
    "with tf.name_scope(\"read_next_train_batch\"):\n",
    "    filenames = tf.placeholder(tf.string, shape=[None])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    dataset = dataset.flat_map(lambda filename: tf.data.TextLineDataset(filename).skip(1).map(decode_csv))\n",
    "    dataset = dataset.batch(minibatch_size)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "\n",
    "# Placeholders to take in batches of data\n",
    "tf_labels = tf.placeholder(dtype=tf.int64, shape=[minibatch_size, 1])\n",
    "tf_predictions = tf.placeholder(dtype=tf.int64, shape=[minibatch_size, 1])    \n",
    "\n",
    "with tf.name_scope(\"precision_per_class_scope\"):\n",
    "    for k in range (num_classes):\n",
    "        precision_per_class[k], update_precision_per_class[k] = tf.metrics.precision(tf_labels, tf_predictions,\n",
    "                                                                                     name=\"precision_class_\"+str(k))\n",
    "\n",
    "with tf.name_scope(\"recall_per_class_scope\"):\n",
    "    for k in range (num_classes):\n",
    "        recall_per_class[k], update_recall_per_class[k] = tf.metrics.recall(tf_labels, tf_predictions,\n",
    "                                                                            name=\"recall_class_\"+str(k)) \n",
    "        \n",
    "with tf.name_scope(\"metric_accuracy_scope\"):\n",
    "    # This will hold the accuracy for the entire set, not only per class\n",
    "    accuracy, accuracy_update = tf.metrics.accuracy(tf_labels,\n",
    "                                                    tf_predictions)\n",
    "\n",
    "init_local = tf.local_variables_initializer() \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_local)   # Local vars need to be initialized to be able to use tf.metrics functions\n",
    "        \n",
    "    sess.run(iterator.initializer, feed_dict={filenames: file_names})\n",
    "    batch_nr = 0\n",
    "    while True:\n",
    "        try:\n",
    "          batch_features, batch_labels = sess.run(next_element)           \n",
    "          \n",
    "          # Update the accuracy based on the current batch\n",
    "          sess.run(accuracy_update, \n",
    "                   feed_dict={tf_labels: batch_labels, \n",
    "                              tf_predictions: train_predictions[batch_nr]})\n",
    "            \n",
    "          # If we have 3 classes, then they will be like class 0, class 1, and class 2.\n",
    "          # When calculating precision for class 0, we will check:\n",
    "          # How many CORRECT class 0 predictions do we have? (True Positive)\n",
    "          # And how many WRONG class 0 predictions do we have? (False Positive)\n",
    "          # And precision for class 0  =  TP_class0 / (TP_Class0 + FP_class0)\n",
    "          for k in range(num_classes):\n",
    "              \n",
    "              # If a given batch_labels = [[0],[0],[0],[1],[1],[2]]\n",
    "              # then the following code will produce: [[True],[True],[True],[False],[False],[False]] for class_0  \n",
    "              labels = np.equal(batch_labels[batch_nr], np.ones(batch_labels.shape)*k)\n",
    "              \n",
    "              batch_predictions = np.equal(train_predictions[batch_nr], np.ones(batch_labels.shape)*k)\n",
    "                \n",
    "              # Update precision and recall for the class=k\n",
    "              sess.run([update_precision_per_class[k], update_recall_per_class[k]], \n",
    "                       feed_dict={tf_labels: labels, \n",
    "                                  tf_predictions: batch_predictions})\n",
    "                \n",
    "          for k in range (num_classes):\n",
    "              print(\"Batch nr: \", batch_nr, \"class: \", k,\n",
    "                    \"  Precision: \", sess.run(precision_per_class[k]),\n",
    "                    \"  Recall:    \", sess.run(recall_per_class[k]),\n",
    "                    \"  Model Accuracy: \", sess.run(accuracy))\n",
    "          \n",
    "          batch_nr += 1\n",
    "            \n",
    "        except tf.errors.OutOfRangeError:\n",
    "          print(\"All data processed.\\n\")\n",
    "          break\n",
    "    \n",
    "    # CALCULATE F1 SCORE PER CLASS. All 3 operations are element-wise\n",
    "    numerator = tf.multiply(2., tf.multiply(precision_per_class, recall_per_class))\n",
    "    denominator= tf.add(precision_per_class, recall_per_class)\n",
    "    f1_score_per_class = tf.divide(numerator, denominator)\n",
    "    \n",
    "    print(\"Summary\\n\")\n",
    "    for k in range (num_classes):\n",
    "        print(\"class: \", k,\n",
    "              \"  Precision:  \", sess.run(precision_per_class[k]),\n",
    "              \"  Recall: \", sess.run(recall_per_class[k]),\n",
    "              \"  F1 Score: \", sess.run(f1_score_per_class[k]),\n",
    "              \"  Model Accuracy: \", sess.run(accuracy))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows an exmaple usage for tf.one_hot(..) and tf.squeeze(..) functions.\n",
    "# When developing NN, one_hot function can be beneficial when you only \n",
    "# have the class number as label (i.e. 0, 1, 2, 3, etc.) If you know\n",
    "# the total number of classes (= # units in output layer), you can easily\n",
    "# construct a matrix of vectors where each vector represents the label \n",
    "# of a given train/dev/test example in the output layer. This can be\n",
    "# needed either when calculating forward prop or cost of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE-1 IN EACH PROJECT (depending on default values for each column)\n",
    "# Determine default values for each column in case data is missing\n",
    "record_defaults = [[\"\"], [0.0], [0.0], [0.0], [0.0], [0.0], [0]]\n",
    "\n",
    "def decode_csv(line):\n",
    "    parsed_line = tf.decode_csv(line, record_defaults)\n",
    "    label = parsed_line[-1:]          # last column is label\n",
    "    del parsed_line[-1]               # delete the last element from the list   (label column)\n",
    "    del parsed_line[0]                # even delete the first element bcz it is assumed NOT to be a feature\n",
    "    features = tf.stack(parsed_line)  # Stack features so that you can later vectorize forward prop., etc.\n",
    "    label = tf.stack(label)           # Needed bcz labels consist of 2 columns\n",
    "    batch_to_return = features, label\n",
    "\n",
    "    return batch_to_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READS DATA FROM train data set CSV FILES, normalizes the data and writes normalized values in a new file.\n",
    "# This preprocessing needs to be done first if input normalization is supposed to be applied prior to training\n",
    "# the actual model.\n",
    "\n",
    "# ASSUMPTIONS: (Otherwise, decode_csv function needs update)\n",
    "# 1) The first column is NOT a feature. (It is most probably a training example ID or similar)\n",
    "# 2) The last column is always the label. And there is ONLY 1 column that represents the label.\n",
    "#    If more than 1 column represents the label, decode_csv() function needs update \n",
    "# 3) The first row is assumed to include names of the data types (i.e. feature name, label, etc.) so it is skipped\n",
    "\n",
    "def apply_one_hot_on_labels(train_input_paths, minibatch_size, num_classes):\n",
    "\n",
    "    with tf.name_scope(\"read_next_train_batch\"):\n",
    "        filenames = tf.placeholder(tf.string, shape=[None])\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "        dataset = dataset.flat_map(lambda filename: tf.data.TextLineDataset(filename).skip(1).map(decode_csv))\n",
    "        dataset = dataset.batch(minibatch_size)\n",
    "        iterator = dataset.make_initializable_iterator()\n",
    "        next_element = iterator.get_next()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(iterator.initializer, feed_dict={filenames: train_input_paths})\n",
    "        while True:\n",
    "            try:\n",
    "              features, labels = sess.run(next_element)\n",
    "              print(\"labels:\\n\", labels)\n",
    "              print(\"labels.shape: \", labels.shape, \"\\n\")\n",
    "              \n",
    "              # apply one_hot  \n",
    "              vectorized_labels = tf.one_hot(labels, depth=num_classes)\n",
    "              print(\"vectorized_labels:\\n\", sess.run(vectorized_labels))\n",
    "              print(\"vectorized_labels.shape: \", vectorized_labels.shape, \"\\n\")\n",
    "            \n",
    "              # one_hot adds one more dimension. Remove that dimension if you don't need it\n",
    "              reduced_dim = tf.squeeze(vectorized_labels, axis=1)\n",
    "              print(\"reduced_dim:\\n\", sess.run(reduced_dim))   \n",
    "              print(\"reduced_dim.shape: \", reduced_dim.shape, \"\\n\")  \n",
    "            except tf.errors.OutOfRangeError:\n",
    "              print(\"All data has been normalized and printed out\")\n",
    "              break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:\n",
      " [[1]\n",
      " [1]\n",
      " [1]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[1]\n",
      " [1]\n",
      " [1]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[1]\n",
      " [1]\n",
      " [0]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[1. 0.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[0]\n",
      " [1]\n",
      " [0]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[1. 0.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[1. 0.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[0]\n",
      " [0]\n",
      " [0]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[0]\n",
      " [1]\n",
      " [1]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[1. 0.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[1]\n",
      " [0]\n",
      " [1]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[0. 1.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[0. 1.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[0]\n",
      " [1]\n",
      " [0]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[1. 0.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[1. 0.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[0]\n",
      " [0]\n",
      " [1]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[0. 1.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[0]\n",
      " [0]\n",
      " [0]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[1. 0.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[0]\n",
      " [0]\n",
      " [1]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[1. 0.]]\n",
      "\n",
      " [[1. 0.]]\n",
      "\n",
      " [[0. 1.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[0]\n",
      " [1]\n",
      " [1]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[1. 0.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[1]\n",
      " [1]\n",
      " [1]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[0. 1.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[0. 1.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[0]\n",
      " [1]\n",
      " [0]]\n",
      "labels.shape:  (3, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[1. 0.]]\n",
      "\n",
      " [[0. 1.]]\n",
      "\n",
      " [[1. 0.]]]\n",
      "vectorized_labels.shape:  (3, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "reduced_dim.shape:  (3, 2) \n",
      "\n",
      "labels:\n",
      " [[1]\n",
      " [0]]\n",
      "labels.shape:  (2, 1) \n",
      "\n",
      "vectorized_labels:\n",
      " [[[0. 1.]]\n",
      "\n",
      " [[1. 0.]]]\n",
      "vectorized_labels.shape:  (2, 1, 2) \n",
      "\n",
      "reduced_dim:\n",
      " [[0. 1.]\n",
      " [1. 0.]]\n",
      "reduced_dim.shape:  (2, 2) \n",
      "\n",
      "All data has been normalized and printed out\n"
     ]
    }
   ],
   "source": [
    "# In this micro project, it is chosen to implement input normalization in a way\n",
    "# so that we first calculate mu and sigma_square values based on the entire train\n",
    "# set. The same mu and sigma_square values will be used in training as well as \n",
    "# when validating the model on dev and test sets. With other words, you do not\n",
    "# re-calculate mu and sigma_square for dev and test sets\n",
    "\n",
    "train_input_paths = [\"train1.csv\", \"train2.csv\"]\n",
    "\n",
    "minibatch_size = 3\n",
    "num_classes = 2\n",
    "\n",
    "apply_one_hot_on_labels(train_input_paths, minibatch_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

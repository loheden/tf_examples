{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# ONE SHOT ITERATOR with for loop\n",
    "\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "      value = sess.run(next_element)\n",
    "      print(value)\n",
    "      assert i == value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# ONE SHOT ITERATOR with for loop\n",
    "\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "      value = sess.run(next_element)\n",
    "      print(value)\n",
    "      assert i == value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Out of range error triggered\n"
     ]
    }
   ],
   "source": [
    "# ONE SHOT ITERATOR with while loop\n",
    "\n",
    "dataset1 = tf.data.Dataset.range(5)\n",
    "iterator1 = dataset1.make_one_shot_iterator()\n",
    "next_element1 = iterator1.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "          value = sess.run(next_element1)\n",
    "          print(value)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "          print(\"Out of range error triggered\")\n",
    "          break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Out of range error triggered (1)\n",
      "\n",
      "Done with the first iterator\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "Out of range error triggered (2)\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZABLE ITERATOR\n",
    "# Reasonable when working with structured data, if you want to periodically (say after each 50th epoch) calculate\n",
    "# cost & accuracy on dev set as well during the training\n",
    "\n",
    "max_value = tf.placeholder(tf.int64, shape=[])\n",
    "dataset2 = tf.data.Dataset.range(max_value)\n",
    "iterator2 = dataset2.make_initializable_iterator()\n",
    "next_element2 = iterator2.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize an iterator over a dataset with 6 elements.\n",
    "    sess.run(iterator2.initializer, feed_dict={max_value: 6})\n",
    "    while True:\n",
    "        try:\n",
    "          value = sess.run(next_element2)\n",
    "          print(value)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "          print(\"Out of range error triggered (1)\")\n",
    "          break\n",
    "\n",
    "    print(\"\\nDone with the first iterator\\n\")\n",
    "            \n",
    "    # Initialize the same iterator over a dataset with 3 elements.\n",
    "    sess.run(iterator2.initializer, feed_dict={max_value: 3})\n",
    "    while True:\n",
    "        try:\n",
    "          value = sess.run(next_element2)\n",
    "          print(value)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "          print(\"Out of range error triggered (2)\")\n",
    "          break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4\n",
      "1\n",
      "2\n",
      "5\n",
      "4\n",
      "4\n",
      "Out of range error triggered (train set)\n",
      "0\n",
      "1\n",
      "2\n",
      "Out of range error triggered (validation set)\n",
      "-3\n",
      "-2\n",
      "-2\n",
      "-1\n",
      "3\n",
      "2\n",
      "Out of range error triggered (train set)\n",
      "0\n",
      "1\n",
      "2\n",
      "Out of range error triggered (validation set)\n"
     ]
    }
   ],
   "source": [
    "# RE-INITIALIZABLE ITERATOR\n",
    "\n",
    "# Define training and validation datasets with the same structure.\n",
    "# In the case of validation_dataset below, the iterator returns 0 in the first call, 1 in the second call, and so on.\n",
    "# training_dataset returns the same too but it sums x (the value to be returned) with a number between -4 and 4.\n",
    "# So when x is 0, then the return value will be between -4 and 4. When x=1, the iterator will return a value between\n",
    "# -3 and 5, and so on.. This is illustrated so to motivate the need for a re-initializable iterator. You might have a\n",
    "# training input pipeline that uses random perturbations to the input images to improve generalization, and a \n",
    "# validation input pipeline that evaluates predictions on unmodified data. These pipelines will typically use \n",
    "# different Dataset objects that have the same structure (i.e. the same types and compatible shapes for each \n",
    "# component)\n",
    "training_dataset = tf.data.Dataset.range(6).map(\n",
    "    lambda x: x + tf.random_uniform([], -4, 4, tf.int64))\n",
    "validation_dataset = tf.data.Dataset.range(3)\n",
    "\n",
    "# A reinitializable iterator is defined by its structure. We could use the\n",
    "# `output_types` and `output_shapes` properties of either `training_dataset`\n",
    "# or `validation_dataset` here, because they are compatible.\n",
    "iterator3 = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
    "                                            training_dataset.output_shapes)\n",
    "next_element3 = iterator3.get_next()\n",
    "\n",
    "training_init_op = iterator3.make_initializer(training_dataset)\n",
    "validation_init_op = iterator3.make_initializer(validation_dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run 2 epochs in which the training dataset is traversed, followed by the\n",
    "    # validation dataset.\n",
    "    numEpochs = 2\n",
    "    for _ in range(numEpochs):\n",
    "      # Initialize an iterator over the training dataset.\n",
    "      sess.run(training_init_op)  \n",
    "      while True:\n",
    "        try:\n",
    "          value = sess.run(next_element3)\n",
    "          print(value)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "          print(\"Out of range error triggered (train set)\")\n",
    "          break\n",
    "            \n",
    "      # Initialize an iterator over the validation dataset.\n",
    "      sess.run(validation_init_op)\n",
    "      while True:\n",
    "        try:\n",
    "          value = sess.run(next_element3)\n",
    "          print(value)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "          print(\"Out of range error triggered (validation set)\")\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "\n",
      "Done with training data\n",
      "\n",
      "0\n",
      "1\n",
      "\n",
      "Done with validation data\n",
      "\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "\n",
      "Done with training data\n",
      "\n",
      "0\n",
      "1\n",
      "\n",
      "Done with validation data\n",
      "\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "\n",
      "Done with training data\n",
      "\n",
      "0\n",
      "1\n",
      "\n",
      "Done with validation data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FEEDABLE ITERATOR\n",
    "# can be used together with tf.placeholder to select what Iterator to use in each call to tf.Session.run, \n",
    "# via the familiar feed_dict mechanism. It offers the same functionality as a reinitializable iterator, but it does \n",
    "# not require you to initialize the iterator from the start of a dataset when you switch between iterators.\n",
    "\n",
    "# Feedable Iterator is particularly useful especially if the (training) dataset size is TOO LARGE, where you\n",
    "# occasionally calculate cost/accuracy of the train set without completing 1 epoch, and the continue with the\n",
    "# training from the point you left.\n",
    "\n",
    "# Define training and validation datasets with the same structure.\n",
    "training_dataset4 = tf.data.Dataset.range(5).map(\n",
    "    lambda x: x + 1).repeat()  #tf.random_uniform([], -3, 3, tf.int64)).repeat()\n",
    "validation_dataset4 = tf.data.Dataset.range(2)\n",
    "\n",
    "# A feedable iterator is defined by a handle placeholder and its structure. We\n",
    "# could use the `output_types` and `output_shapes` properties of either\n",
    "# `training_dataset` or `validation_dataset` here, because they have\n",
    "# identical structure.\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator4 = tf.data.Iterator.from_string_handle(\n",
    "    handle, training_dataset4.output_types, training_dataset4.output_shapes)\n",
    "next_element4 = iterator4.get_next()\n",
    "\n",
    "# You can use feedable iterators with a variety of different kinds of iterator\n",
    "# (such as one-shot and initializable iterators).\n",
    "training_iterator4 = training_dataset4.make_one_shot_iterator()\n",
    "validation_iterator4 = validation_dataset4.make_initializable_iterator()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # The `Iterator.string_handle()` method returns a tensor that can be evaluated\n",
    "    # and used to feed the `handle` placeholder.\n",
    "    training_handle = sess.run(training_iterator4.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator4.string_handle())\n",
    "\n",
    "    # You can loop forever, alternating between training and validation.\n",
    "    # For simplicity, we only loop 3 times here\n",
    "    for _ in range(3):\n",
    "      for _ in range(7):  # Even if range=5 in training_dataset4 definition above, we have the repeat() which enables looping more than 5 times\n",
    "         # Run 7 steps using the training dataset. Note that the training dataset is\n",
    "         # infinite, and we resume from where we left off in the previous `for` loop\n",
    "         # iteration.\n",
    "         print(sess.run(next_element4, feed_dict={handle: training_handle}))\n",
    "      \n",
    "      print(\"\\nDone with training data\\n\")\n",
    "    \n",
    "      # Run one pass over the validation dataset. (1 epoch over validation dataset)\n",
    "      sess.run(validation_iterator4.initializer)\n",
    "      for _ in range(2):  # Since the range is set to 2 for validation_dataset4 above, this has to be 2\n",
    "         print(sess.run(next_element4, feed_dict={handle: validation_handle}))\n",
    "        \n",
    "      print(\"\\nDone with validation data\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) features: \n",
      "[[17. 17. 17. 17. 17.]\n",
      " [27. 27. 27. 27. 27.]\n",
      " [ 5.  5.  5.  5.  5.]\n",
      " [22. 22. 22. 22. 22.]\n",
      " [13. 13. 13. 13. 13.]\n",
      " [25. 25. 25. 25. 25.]\n",
      " [18. 18. 18. 18. 18.]]\n",
      "(train) labels: \n",
      "[33. 53.  9. 43. 25. 49. 35.]\n",
      "(train) features: \n",
      "[[ 7.  7.  7.  7.  7.]\n",
      " [19. 19. 19. 19. 19.]\n",
      " [15. 15. 15. 15. 15.]\n",
      " [14. 14. 14. 14. 14.]\n",
      " [28. 28. 28. 28. 28.]\n",
      " [26. 26. 26. 26. 26.]\n",
      " [23. 23. 23. 23. 23.]]\n",
      "(train) labels: \n",
      "[13. 37. 29. 27. 55. 51. 45.]\n",
      "(train) features: \n",
      "[[ 1.  1.  1.  1.  1.]\n",
      " [12. 12. 12. 12. 12.]\n",
      " [ 6.  6.  6.  6.  6.]\n",
      " [ 3.  3.  3.  3.  3.]\n",
      " [ 2.  2.  2.  2.  2.]\n",
      " [ 8.  8.  8.  8.  8.]\n",
      " [16. 16. 16. 16. 16.]]\n",
      "(train) labels: \n",
      "[ 1. 23. 11.  5.  3. 15. 31.]\n",
      "(train) features: \n",
      "[[ 4.  4.  4.  4.  4.]\n",
      " [20. 20. 20. 20. 20.]\n",
      " [21. 21. 21. 21. 21.]\n",
      " [10. 10. 10. 10. 10.]\n",
      " [24. 24. 24. 24. 24.]\n",
      " [ 9.  9.  9.  9.  9.]\n",
      " [11. 11. 11. 11. 11.]]\n",
      "(train) labels: \n",
      "[ 7. 39. 41. 19. 47. 17. 21.]\n",
      "Out of range error triggered (looped through training set 1 time)\n",
      "(train) features: \n",
      "[[27. 27. 27. 27. 27.]\n",
      " [18. 18. 18. 18. 18.]\n",
      " [16. 16. 16. 16. 16.]\n",
      " [11. 11. 11. 11. 11.]\n",
      " [23. 23. 23. 23. 23.]\n",
      " [14. 14. 14. 14. 14.]\n",
      " [22. 22. 22. 22. 22.]]\n",
      "(train) labels: \n",
      "[53. 35. 31. 21. 45. 27. 43.]\n",
      "(train) features: \n",
      "[[ 3.  3.  3.  3.  3.]\n",
      " [ 9.  9.  9.  9.  9.]\n",
      " [13. 13. 13. 13. 13.]\n",
      " [17. 17. 17. 17. 17.]\n",
      " [12. 12. 12. 12. 12.]\n",
      " [26. 26. 26. 26. 26.]\n",
      " [ 4.  4.  4.  4.  4.]]\n",
      "(train) labels: \n",
      "[ 5. 17. 25. 33. 23. 51.  7.]\n",
      "(train) features: \n",
      "[[19. 19. 19. 19. 19.]\n",
      " [ 6.  6.  6.  6.  6.]\n",
      " [10. 10. 10. 10. 10.]\n",
      " [15. 15. 15. 15. 15.]\n",
      " [ 7.  7.  7.  7.  7.]\n",
      " [25. 25. 25. 25. 25.]\n",
      " [28. 28. 28. 28. 28.]]\n",
      "(train) labels: \n",
      "[37. 11. 19. 29. 13. 49. 55.]\n",
      "(train) features: \n",
      "[[ 2.  2.  2.  2.  2.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 5.  5.  5.  5.  5.]\n",
      " [21. 21. 21. 21. 21.]\n",
      " [24. 24. 24. 24. 24.]\n",
      " [20. 20. 20. 20. 20.]\n",
      " [ 8.  8.  8.  8.  8.]]\n",
      "(train) labels: \n",
      "[ 3.  1.  9. 41. 47. 39. 15.]\n",
      "Out of range error triggered (looped through training set 1 time)\n",
      "\n",
      "Done with the first iterator\n",
      "\n",
      "(dev) features: \n",
      "[[102. 102. 102. 102. 102.]\n",
      " [109. 109. 109. 109. 109.]\n",
      " [101. 101. 101. 101. 101.]\n",
      " [108. 108. 108. 108. 108.]\n",
      " [106. 106. 106. 106. 106.]\n",
      " [107. 107. 107. 107. 107.]\n",
      " [105. 105. 105. 105. 105.]]\n",
      "(dev) labels: \n",
      "[205. 219. 203. 217. 213. 215. 211.]\n",
      "(dev) features: \n",
      "[[113. 113. 113. 113. 113.]\n",
      " [103. 103. 103. 103. 103.]\n",
      " [100. 100. 100. 100. 100.]\n",
      " [111. 111. 111. 111. 111.]\n",
      " [110. 110. 110. 110. 110.]\n",
      " [104. 104. 104. 104. 104.]\n",
      " [112. 112. 112. 112. 112.]]\n",
      "(dev) labels: \n",
      "[227. 207. 201. 223. 221. 209. 225.]\n",
      "Out of range error triggered (looped through dev set 1 time only)\n"
     ]
    }
   ],
   "source": [
    "# READING DATA FROM train and validation (dev set) CSV FILES by using INITIALIZABLE ITERATORS\n",
    "\n",
    "# All csv files have same # columns. First column is assumed to be train example ID, the next 5 columns are feature\n",
    "# columns, and the last column is the label column\n",
    "\n",
    "# ASSUMPTIONS: (Otherwise, decode_csv function needs update)\n",
    "# 1) The first column is NOT a feature. (It is most probably a training example ID or similar)\n",
    "# 2) The last column is always the label. And there is ONLY 1 column that represents the label.\n",
    "#    If more than 1 column represents the label, see the next example down below\n",
    "\n",
    "feature_names = ['f1','f2','f3','f4','f5']\n",
    "record_defaults = [[\"\"], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
    "\n",
    "\n",
    "def decode_csv(line):\n",
    "   parsed_line = tf.decode_csv(line, record_defaults)\n",
    "   label =  parsed_line[-1]      # label is the last element of the list\n",
    "   del parsed_line[-1]           # delete the last element from the list\n",
    "   del parsed_line[0]            # even delete the first element bcz it is assumed NOT to be a feature\n",
    "   features = tf.stack(parsed_line)  # Stack features so that you can later vectorize forward prop., etc.\n",
    "   #label = tf.stack(label)          #NOT needed. Only if more than 1 column makes the label...\n",
    "   batch_to_return = features, label\n",
    "   return batch_to_return\n",
    "   \n",
    "filenames = tf.placeholder(tf.string, shape=[None])\n",
    "dataset5 = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "dataset5 = dataset5.flat_map(lambda filename: tf.data.TextLineDataset(filename).skip(1).map(decode_csv))\n",
    "dataset5 = dataset5.shuffle(buffer_size=1000)\n",
    "dataset5 = dataset5.batch(7)\n",
    "iterator5 = dataset5.make_initializable_iterator()\n",
    "next_element5 = iterator5.get_next()\n",
    "\n",
    "# Initialize `iterator` with training data.\n",
    "training_filenames = [\"train_data1.csv\", \n",
    "                      \"train_data2.csv\"]\n",
    "\n",
    "# Initialize `iterator` with validation data.\n",
    "validation_filenames = [\"dev_data1.csv\"]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Train 2 epochs. Then validate train set. Then validate dev set.\n",
    "    for _ in range(2):     \n",
    "        sess.run(iterator5.initializer, feed_dict={filenames: training_filenames})\n",
    "        while True:\n",
    "            try:\n",
    "              features, labels = sess.run(next_element5)\n",
    "              # Train...\n",
    "              print(\"(train) features: \")\n",
    "              print(features)\n",
    "              print(\"(train) labels: \")\n",
    "              print(labels)  \n",
    "            except tf.errors.OutOfRangeError:\n",
    "              print(\"Out of range error triggered (looped through training set 1 time)\")\n",
    "              break\n",
    "\n",
    "    # Validate (cost, accuracy) on train set\n",
    "    print(\"\\nDone with the first iterator\\n\")\n",
    "            \n",
    "    sess.run(iterator5.initializer, feed_dict={filenames: validation_filenames})\n",
    "    while True:\n",
    "        try:\n",
    "          features, labels = sess.run(next_element5)\n",
    "          # Validate (cost, accuracy) on dev set\n",
    "          print(\"(dev) features: \")\n",
    "          print(features)\n",
    "          print(\"(dev) labels: \")\n",
    "          print(labels)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "          print(\"Out of range error triggered (looped through dev set 1 time only)\")\n",
    "          break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) features: \n",
      "[[ 9.  9.  9.  9.]\n",
      " [19. 19. 19. 19.]\n",
      " [15. 15. 15. 15.]\n",
      " [21. 21. 21. 21.]\n",
      " [ 6.  6.  6.  6.]\n",
      " [27. 27. 27. 27.]\n",
      " [12. 12. 12. 12.]]\n",
      "(train) labels: \n",
      "[[ 9. 17.]\n",
      " [19. 37.]\n",
      " [15. 29.]\n",
      " [21. 41.]\n",
      " [ 6. 11.]\n",
      " [27. 53.]\n",
      " [12. 23.]]\n",
      "(train) features: \n",
      "[[10. 10. 10. 10.]\n",
      " [ 3.  3.  3.  3.]\n",
      " [20. 20. 20. 20.]\n",
      " [ 4.  4.  4.  4.]\n",
      " [18. 18. 18. 18.]\n",
      " [23. 23. 23. 23.]\n",
      " [ 2.  2.  2.  2.]]\n",
      "(train) labels: \n",
      "[[10. 19.]\n",
      " [ 3.  5.]\n",
      " [20. 39.]\n",
      " [ 4.  7.]\n",
      " [18. 35.]\n",
      " [23. 45.]\n",
      " [ 2.  3.]]\n",
      "(train) features: \n",
      "[[11. 11. 11. 11.]\n",
      " [ 5.  5.  5.  5.]\n",
      " [28. 28. 28. 28.]\n",
      " [16. 16. 16. 16.]\n",
      " [14. 14. 14. 14.]\n",
      " [24. 24. 24. 24.]\n",
      " [ 7.  7.  7.  7.]]\n",
      "(train) labels: \n",
      "[[11. 21.]\n",
      " [ 5.  9.]\n",
      " [28. 55.]\n",
      " [16. 31.]\n",
      " [14. 27.]\n",
      " [24. 47.]\n",
      " [ 7. 13.]]\n",
      "(train) features: \n",
      "[[ 8.  8.  8.  8.]\n",
      " [26. 26. 26. 26.]\n",
      " [17. 17. 17. 17.]\n",
      " [22. 22. 22. 22.]\n",
      " [ 1.  1.  1.  1.]\n",
      " [25. 25. 25. 25.]\n",
      " [13. 13. 13. 13.]]\n",
      "(train) labels: \n",
      "[[ 8. 15.]\n",
      " [26. 51.]\n",
      " [17. 33.]\n",
      " [22. 43.]\n",
      " [ 1.  1.]\n",
      " [25. 49.]\n",
      " [13. 25.]]\n",
      "Out of range error triggered (looped through training set 1 time)\n",
      "(train) features: \n",
      "[[28. 28. 28. 28.]\n",
      " [15. 15. 15. 15.]\n",
      " [ 7.  7.  7.  7.]\n",
      " [17. 17. 17. 17.]\n",
      " [10. 10. 10. 10.]\n",
      " [16. 16. 16. 16.]\n",
      " [23. 23. 23. 23.]]\n",
      "(train) labels: \n",
      "[[28. 55.]\n",
      " [15. 29.]\n",
      " [ 7. 13.]\n",
      " [17. 33.]\n",
      " [10. 19.]\n",
      " [16. 31.]\n",
      " [23. 45.]]\n",
      "(train) features: \n",
      "[[27. 27. 27. 27.]\n",
      " [ 9.  9.  9.  9.]\n",
      " [24. 24. 24. 24.]\n",
      " [20. 20. 20. 20.]\n",
      " [ 3.  3.  3.  3.]\n",
      " [ 1.  1.  1.  1.]\n",
      " [11. 11. 11. 11.]]\n",
      "(train) labels: \n",
      "[[27. 53.]\n",
      " [ 9. 17.]\n",
      " [24. 47.]\n",
      " [20. 39.]\n",
      " [ 3.  5.]\n",
      " [ 1.  1.]\n",
      " [11. 21.]]\n",
      "(train) features: \n",
      "[[13. 13. 13. 13.]\n",
      " [26. 26. 26. 26.]\n",
      " [ 5.  5.  5.  5.]\n",
      " [12. 12. 12. 12.]\n",
      " [21. 21. 21. 21.]\n",
      " [ 6.  6.  6.  6.]\n",
      " [19. 19. 19. 19.]]\n",
      "(train) labels: \n",
      "[[13. 25.]\n",
      " [26. 51.]\n",
      " [ 5.  9.]\n",
      " [12. 23.]\n",
      " [21. 41.]\n",
      " [ 6. 11.]\n",
      " [19. 37.]]\n",
      "(train) features: \n",
      "[[22. 22. 22. 22.]\n",
      " [18. 18. 18. 18.]\n",
      " [14. 14. 14. 14.]\n",
      " [25. 25. 25. 25.]\n",
      " [ 2.  2.  2.  2.]\n",
      " [ 4.  4.  4.  4.]\n",
      " [ 8.  8.  8.  8.]]\n",
      "(train) labels: \n",
      "[[22. 43.]\n",
      " [18. 35.]\n",
      " [14. 27.]\n",
      " [25. 49.]\n",
      " [ 2.  3.]\n",
      " [ 4.  7.]\n",
      " [ 8. 15.]]\n",
      "Out of range error triggered (looped through training set 1 time)\n",
      "\n",
      "Done with the first iterator\n",
      "\n",
      "(dev) features: \n",
      "[[108. 108. 108. 108.]\n",
      " [113. 113. 113. 113.]\n",
      " [104. 104. 104. 104.]\n",
      " [102. 102. 102. 102.]\n",
      " [109. 109. 109. 109.]\n",
      " [100. 100. 100. 100.]\n",
      " [112. 112. 112. 112.]]\n",
      "(dev) labels: \n",
      "[[108. 217.]\n",
      " [113. 227.]\n",
      " [104. 209.]\n",
      " [102. 205.]\n",
      " [109. 219.]\n",
      " [100. 201.]\n",
      " [112. 225.]]\n",
      "(dev) features: \n",
      "[[110. 110. 110. 110.]\n",
      " [103. 103. 103. 103.]\n",
      " [107. 107. 107. 107.]\n",
      " [111. 111. 111. 111.]\n",
      " [106. 106. 106. 106.]\n",
      " [105. 105. 105. 105.]\n",
      " [101. 101. 101. 101.]]\n",
      "(dev) labels: \n",
      "[[110. 221.]\n",
      " [103. 207.]\n",
      " [107. 215.]\n",
      " [111. 223.]\n",
      " [106. 213.]\n",
      " [105. 211.]\n",
      " [101. 203.]]\n",
      "Out of range error triggered (looped through dev set 1 time only)\n"
     ]
    }
   ],
   "source": [
    "# READING DATA FROM train and validation (dev set) CSV FILES by using INITIALIZABLE ITERATORS\n",
    "\n",
    "# All csv files have same # columns. First column is assumed to be train example ID, the next 4 columns are feature\n",
    "# columns, and the last 2 columns are the label columns\n",
    "\n",
    "# ASSUMPTIONS: (Otherwise, decode_csv function needs update)\n",
    "# 1) The first column is NOT a feature. (It is most probably a training example ID or similar)\n",
    "# 2) The last 2 columns are always the label columns. (It could have been 3, 4, etc. Then update the decode_csv func.)\n",
    "\n",
    "feature_names = ['f1','f2','f3','f4']  # Not used below. Just for illustration.\n",
    "record_defaults = [[\"\"], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
    "\n",
    "\n",
    "def decode_csv2(line):\n",
    "   parsed_line = tf.decode_csv(line, record_defaults)\n",
    "   label = parsed_line[-2:]     # last 2 columns are labels\n",
    "   del parsed_line[-1]           # delete the last element from the list   (label column)\n",
    "   del parsed_line[-2]           # delete the second last element from the list. (label column)\n",
    "   del parsed_line[0]            # even delete the first element bcz it is assumed NOT to be a feature\n",
    "   features = tf.stack(parsed_line)  # Stack features so that you can later vectorize forward prop., etc.\n",
    "   label = tf.stack(label)          #NOT needed. If a vector needs to be constructed (e.g. for softmax), then maybe..\n",
    "   batch_to_return = features, label\n",
    "   return batch_to_return\n",
    "   \n",
    "filenames6 = tf.placeholder(tf.string, shape=[None])\n",
    "dataset6 = tf.data.Dataset.from_tensor_slices(filenames6)\n",
    "dataset6 = dataset6.flat_map(lambda filename: tf.data.TextLineDataset(filename).skip(1).map(decode_csv2))\n",
    "dataset6 = dataset6.shuffle(buffer_size=1000)\n",
    "dataset6 = dataset6.batch(7)\n",
    "iterator6 = dataset6.make_initializable_iterator()\n",
    "next_element6 = iterator6.get_next()\n",
    "\n",
    "# Initialize `iterator` with training data.\n",
    "training_filenames = [\"train_data1.csv\", \n",
    "                      \"train_data2.csv\"]\n",
    "\n",
    "# Initialize `iterator` with validation data.\n",
    "validation_filenames = [\"dev_data1.csv\"]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Train 2 epochs. Then validate train set. Then validate dev set.\n",
    "    for _ in range(2):     \n",
    "        sess.run(iterator6.initializer, feed_dict={filenames6: training_filenames})\n",
    "        while True:\n",
    "            try:\n",
    "              features, labels = sess.run(next_element6)\n",
    "              # Train...\n",
    "              print(\"(train) features: \")\n",
    "              print(features)\n",
    "              print(\"(train) labels: \")\n",
    "              print(labels)  \n",
    "            except tf.errors.OutOfRangeError:\n",
    "              print(\"Out of range error triggered (looped through training set 1 time)\")\n",
    "              break\n",
    "\n",
    "    # Validate (cost, accuracy) on train set\n",
    "    print(\"\\nDone with the first iterator\\n\")\n",
    "            \n",
    "    sess.run(iterator6.initializer, feed_dict={filenames6: validation_filenames})\n",
    "    while True:\n",
    "        try:\n",
    "          features, labels = sess.run(next_element6)\n",
    "          # Validate (cost, accuracy) on dev set\n",
    "          print(\"(dev) features: \")\n",
    "          print(features)\n",
    "          print(\"(dev) labels: \")\n",
    "          print(labels)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "          print(\"Out of range error triggered (looped through dev set 1 time only)\")\n",
    "          break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
